{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4e6445",
   "metadata": {},
   "source": [
    "# 01 — Basics Overview (Runnable)\n",
    "\n",
    "This notebook contains runnable examples that work without external LLM SDKs. It includes a tiny environment loader (no dependencies required), a message structure demo, prompt templating, and an improved `Memory` class that limits by characters. If you want to connect to a real LLM (Foundry or similar), see the `docs/roadmap.md` for secure configuration using a local `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal environment loader that does NOT require python-dotenv\n",
    "# It reads a `.env` file at project root if present and sets os.environ entries.\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_dotenv_if_present(dotenv_path='.env'):\n",
    "    p = Path(dotenv_path)\n",
    "    if not p.exists():\n",
    "        print('No .env file found at', p.resolve())\n",
    "        return {}\n",
    "    data = {}\n",
    "    with p.open() as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            if '=' not in line:\n",
    "                continue\n",
    "            k, v = line.split('=', 1)\n",
    "            k = k.strip()\n",
    "            v = v.strip().strip('\"').strip('\"')\n",
    "            os.environ.setdefault(k, v)\n",
    "            data[k] = v\n",
    "    print('Loaded', len(data), 'entries from', p)\n",
    "    return data\n",
    "\n",
    "# Run loader (safe) — will not overwrite existing env vars\n",
    "_loaded_env = load_dotenv_if_present()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f88f7",
   "metadata": {},
   "source": [
    "## LLM Chat Structure (Conceptual)\n",
    "\n",
    "LLM chat systems use a list of messages with roles: `system`, `user`, and `assistant`. The `system` message sets behavior, `user` provides instructions or queries, and `assistant` contains model outputs. We'll demonstrate how this structure maps to function calls and simple agent loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0170e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 6) (1089637377.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"Messages structure:\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 6)\n"
     ]
    }
   ],
   "source": [
    "# Example: message structure example (no external API)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Summarize the dataset columns for me.\"},\n",
    "]\n",
    "print('Messages structure:', messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8b137",
   "metadata": {},
   "source": [
    "## Prompt Design (Short)\n",
    "Prompts guide model behavior. Start with a clear `system` instruction, then provide context and ask concise questions. Use few-shot examples for structure when needed. The example below uses Python's `string.Template` which is built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de214edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template example using built-in Template\n",
    "from string import Template\n",
    "template = Template('System: $system\\nUser: $user_prompt')\n",
    "print(template.substitute(system='You summarize tables', user_prompt='Describe columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf0108",
   "metadata": {},
   "source": [
    "## Memory (Runnable Implementation)\n",
    "Memory stores the conversation history or facts about the user. Below is a small implementation that limits stored characters (not messages) and can convert memory into a compact system prompt for future LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory class that limits stored characters and can produce a system prompt\n",
    "class Memory:\n",
    "    def __init__(self, char_limit=500):\n",
    "        self.char_limit = int(char_limit)\n",
    "        self.history = []\n",
    "        self._total_chars = 0\n",
    "    def add(self, role, content):\n",
    "        item = {\"role\": role, \"content\": content}\n",
    "        self.history.append(item)\n",
    "        self._total_chars += len(content)\n",
    "        # Trim oldest until under limit\n",
    "        while self._total_chars > self.char_limit and self.history:\n",
    "            removed = self.history.pop(0)\n",
    "            self._total_chars -= len(removed['content'])\n",
    "    def summarize(self, max_items=5):\n",
    "        return ' | '.join(m['content'] for m in self.history[-max_items:])\n",
    "    def to_system_prompt(self):\n",
    "        # Convert recent memory into a single system prompt string\n",
    "        if not self.history:\n",
    "            return ''\n",
    "        return 'Memory summary: ' + self.summarize()\n",
    "\n",
    "# Demo\n",
    "mem = Memory(char_limit=200)\n",
    "mem.add('user', 'I like data visualization and prefer seaborn for quick plots.')\n",
    "mem.add('assistant', 'Noted — I will suggest charts and colors.')\n",
    "mem.add('user', 'I often work with time series.')\n",
    "print('System prompt built from memory:')\n",
    "print(mem.to_system_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59c6ea",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "- Modify the `Memory` class to add metadata tags (e.g., `project`, `priority`) to messages and filter by tag when building a system prompt.\n",
    "- Write a function that converts the memory into a structured system prompt with bullet points for the LLM.\n",
    "\n",
    "---\n",
    "End of `01_basics_overview.ipynb`. Continue with `02_code_examples.ipynb` for runnable code examples calling local dummy tools and structured explanations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
