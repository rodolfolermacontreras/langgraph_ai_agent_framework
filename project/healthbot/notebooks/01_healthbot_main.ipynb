{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd2c7c9",
   "metadata": {},
   "source": [
    "# HealthBot: AI-Powered Medical Information Agent\n",
    "## Interactive Workflow for Health Education\n",
    "\n",
    "This notebook demonstrates a complete AI agent system that:\n",
    "1. Takes patient health topics\n",
    "2. Searches medical information via Tavily\n",
    "3. Summarizes findings at an 8th-grade reading level\n",
    "4. Generates quiz questions to assess understanding\n",
    "5. Grades answers with detailed feedback\n",
    "\n",
    "**Stand-out Feature**: For each health topic, the system generates NEW quiz questions as you practice, enabling deeper learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Annotated, Optional, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "print('All imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path(r'c:\\Training\\Udacity\\AI_Agents_LangGraph\\project')\n",
    "env_path = project_root / '.env'\n",
    "\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError('OPENAI_API_KEY not found')\n",
    "if not tavily_api_key:\n",
    "    raise ValueError('TAVILY_API_KEY not found')\n",
    "\n",
    "print(f'Env loaded from: {env_path}')\n",
    "print(f'OpenAI key: {bool(openai_api_key)}')\n",
    "print(f'Tavily key: {bool(tavily_api_key)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643eb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "\n",
    "print(f'LLM: {llm.model_name}')\n",
    "print(f'Temperature: {llm.temperature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf09ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(max_results=5, api_key=tavily_api_key)\n",
    "\n",
    "print(f'Tavily tool initialized')\n",
    "print(f'Max results: {tavily_tool.max_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf239a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthBotState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "    health_topic: Optional[str]\n",
    "    search_results: Optional[str]\n",
    "    summary: Optional[str]\n",
    "    quiz_question: Optional[str]\n",
    "    patient_answer: Optional[str]\n",
    "    grade: Optional[str]\n",
    "    feedback: Optional[str]\n",
    "    should_continue: str\n",
    "    quiz_count: int\n",
    "\n",
    "print(f'State schema defined with {len(HealthBotState.__annotations__)} fields')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10711b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Annotated, Optional, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain and LangGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "print('All imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c70d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup project paths\n",
    "project_root = Path(r'c:\\Training\\Udacity\\AI_Agents_LangGraph\\project')\n",
    "env_path = project_root / '.env'\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Verify credentials are loaded\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError('OPENAI_API_KEY not found in .env')\n",
    "if not tavily_api_key:\n",
    "    raise ValueError('TAVILY_API_KEY not found in .env')\n",
    "\n",
    "print(f'Project root: {project_root}')\n",
    "print(f'OpenAI API key loaded: {bool(openai_api_key)}')\n",
    "print(f'Tavily API key loaded: {bool(tavily_api_key)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df7ff9",
   "metadata": {},
   "source": [
    "## Step 1: Initialize LLM\n",
    "\n",
    "Create the OpenAI language model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63207268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI LLM\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "\n",
    "print('LLM initialized: gpt-3.5-turbo')\n",
    "print(f'Model: {llm.model_name}')\n",
    "print(f'Temperature: {llm.temperature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb6f37",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Tavily Search Tool\n",
    "\n",
    "Create the medical search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6083795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tavily search tool\n",
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=5,\n",
    "    api_key=tavily_api_key\n",
    ")\n",
    "\n",
    "print('Tavily search tool initialized')\n",
    "print(f'Max results per search: {tavily_tool.max_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9299a",
   "metadata": {},
   "source": [
    "## Step 3: Define State Schema\n",
    "\n",
    "Define all state fields that flow through the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120500ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthBotState(TypedDict):\n",
    "    '''State schema for HealthBot workflow'''\n",
    "    messages: Annotated[List, add_messages]  # Conversation history\n",
    "    health_topic: Optional[str]              # Patient's health topic\n",
    "    search_results: Optional[str]            # Raw Tavily search results\n",
    "    summary: Optional[str]                   # LLM-generated summary\n",
    "    quiz_question: Optional[str]             # Generated quiz question\n",
    "    patient_answer: Optional[str]            # Patient's answer to quiz\n",
    "    grade: Optional[str]                     # Letter grade (A-F)\n",
    "    feedback: Optional[str]                  # Grading feedback with citations\n",
    "    should_continue: str                     # 'start', 'continue', or 'exit'\n",
    "    quiz_count: int                          # Number of quiz questions asked\n",
    "\n",
    "print('State schema defined:')\n",
    "print(f'Fields: {list(HealthBotState.__annotations__.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30b75b",
   "metadata": {},
   "source": [
    "## Setup: Environment and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d252339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project root: c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\n",
      "✓ Credentials loaded: OpenAI=True, Tavily=True\n",
      "✓ Ready to run HealthBot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Project paths\n",
    "project_root = Path(r\"c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\")\n",
    "src_path = project_root / \"healthbot\" / \"src\"\n",
    "\n",
    "# Load credentials from .env\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Mark that env is loaded so modules skip redundant loading\n",
    "os.environ['ENV_ALREADY_LOADED'] = 'true'\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Credentials loaded: OpenAI={bool(openai_key)}, Tavily={bool(tavily_key)}\")\n",
    "print(f\"✓ Ready to run HealthBot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3123f",
   "metadata": {},
   "source": [
    "## Import and Initialize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a9ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Workflow imported and compiled\n",
      "✓ Ready for interactive session\n"
     ]
    }
   ],
   "source": [
    "# Import workflow components\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "# Create the compiled workflow\n",
    "app = create_healthbot_workflow()\n",
    "\n",
    "print(\"✓ Workflow imported and compiled\")\n",
    "print(\"✓ Ready for interactive session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14f6f2",
   "metadata": {},
   "source": [
    "## Run Interactive HealthBot Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "# Configuration with thread ID for checkpointing\n",
    "config = {\"configurable\": {\"thread_id\": \"notebook-session-1\"}}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Run the workflow\n",
    "try:\n",
    "    result = app.invoke(initial_state, config)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66705aa",
   "metadata": {},
   "source": [
    "## Architecture: 8-Node AI Agent Workflow\n",
    "\n",
    "### Core Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic** - Interactive input: Collects patient's health topic\n",
    "2. **search_medical_info** - Tavily API: Searches for credible medical sources\n",
    "3. **summarize_results** - LLM processing: Creates 8th-grade-level summary\n",
    "4. **present_summary** - Display: Shows summary and sources\n",
    "5. **generate_quiz** - LLM processing: Generates NEW quiz question each time\n",
    "6. **present_quiz** - Display: Shows question with 4 multiple choice options\n",
    "7. **evaluate_answer** - LLM processing: Grades answer with detailed feedback\n",
    "8. **ask_continue** - Conditional Routing (3-way junction):\n",
    "   - \"q\" → Route back to Node 5 (new question on same topic)\n",
    "   - \"t\" → Route to Node 1 (new topic)\n",
    "   - \"e\" → End session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "**Key Differentiator**: Each quiz question is AI-generated in real-time, NOT pre-created:\n",
    "- Node 5 explicitly instructs the LLM to create a NEW question never before asked\n",
    "- Same topic can produce unlimited unique questions\n",
    "- Enables **comprehensive topic mastery** through multiple angles\n",
    "- Prevents **rote memorization** - students must deeply understand\n",
    "- Multiple **learning reinforcement checkpoints**\n",
    "\n",
    "### Technical Implementation:\n",
    "- **Framework**: LangGraph 0.2.19 (graph-based state machine)\n",
    "- **Language Model**: OpenAI GPT-3.5-turbo\n",
    "- **Search Engine**: Tavily API (medical information retrieval)\n",
    "- **State Management**: 10-field state with thread-based checkpointing\n",
    "- **Execution Model**: Synchronous invoke with user interaction via input()\n",
    "\n",
    "### Data Flow:\n",
    "```\n",
    "User Input → Topic Search → LLM Summary → Display → \n",
    "LLM Generate Question → Display Question → User Answer → \n",
    "LLM Evaluate → Display Grade → Router Decision → \n",
    "(More Q / New Topic / Exit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba7d78",
   "metadata": {},
   "source": [
    "## Setup: Environment and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd503529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Project paths\n",
    "project_root = Path(r\"c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\")\n",
    "src_path = project_root / \"healthbot\" / \"src\"\n",
    "\n",
    "# Load credentials from .env\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Mark that env is loaded so modules skip redundant loading\n",
    "os.environ['ENV_ALREADY_LOADED'] = 'true'\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Credentials loaded: OpenAI={bool(openai_key)}, Tavily={bool(tavily_key)}\")\n",
    "print(f\"✓ Ready to run HealthBot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876631f4",
   "metadata": {},
   "source": [
    "## Import and Initialize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98431905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import workflow components\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "# Create the compiled workflow\n",
    "app = create_healthbot_workflow()\n",
    "\n",
    "print(\"✓ Workflow imported and compiled\")\n",
    "print(\"✓ Ready for interactive session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c019327",
   "metadata": {},
   "source": [
    "## Run Interactive HealthBot Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17303ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "# Configuration with thread ID for checkpointing\n",
    "config = {\"configurable\": {\"thread_id\": \"notebook-session-1\"}}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Run the workflow\n",
    "try:\n",
    "    result = app.invoke(initial_state, config)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea742e2",
   "metadata": {},
   "source": [
    "## Architecture Overview: 8-Node AI Agent Workflow\n",
    "\n",
    "### Core Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic** - Interactive input: Collects patient's health topic\n",
    "2. **search_medical_info** - Tavily API: Searches for credible medical sources\n",
    "3. **summarize_results** - LLM processing: Creates 8th-grade-level summary\n",
    "4. **present_summary** - Display: Shows summary and sources\n",
    "5. **generate_quiz** - LLM processing: Generates NEW quiz question each time\n",
    "6. **present_quiz** - Display: Shows question with 4 multiple choice options\n",
    "7. **evaluate_answer** - LLM processing: Grades answer with detailed feedback\n",
    "8. **ask_continue** - Conditional Routing (3-way junction):\n",
    "   - \"q\" → Route back to Node 5 (new question on same topic)\n",
    "   - \"t\" → Route to Node 1 (new topic)\n",
    "   - \"e\" → End session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "**Key Differentiator**: Each quiz question is AI-generated in real-time, NOT pre-created:\n",
    "- Node 5 explicitly instructs the LLM to create a NEW question never before asked\n",
    "- Same topic can produce unlimited unique questions\n",
    "- Enables **comprehensive topic mastery** through multiple angles\n",
    "- Prevents **rote memorization** - students must deeply understand\n",
    "- Multiple **learning reinforcement checkpoints**\n",
    "\n",
    "### Technical Implementation:\n",
    "- **Framework**: LangGraph 0.2.19 (graph-based state machine)\n",
    "- **Language Model**: OpenAI GPT-3.5-turbo\n",
    "- **Search Engine**: Tavily API (medical information retrieval)\n",
    "- **State Management**: 10-field state with thread-based checkpointing\n",
    "- **Execution Model**: Synchronous invoke with user interaction via input()\n",
    "\n",
    "### Data Flow:\n",
    "```\n",
    "User Input → Topic Search → LLM Summary → Display → \n",
    "LLM Generate Question → Display Question → User Answer → \n",
    "LLM Evaluate → Display Grade → Router Decision → \n",
    "(More Q / New Topic / Exit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da2726",
   "metadata": {},
   "source": [
    "## Setup: Environment & Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Project paths\n",
    "project_root = Path(r\"c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\")\n",
    "src_path = project_root / \"healthbot\" / \"src\"\n",
    "\n",
    "# Load credentials from .env\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Mark that env is loaded so modules skip redundant loading\n",
    "os.environ['ENV_ALREADY_LOADED'] = 'true'\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Credentials loaded: OpenAI={bool(openai_key)}, Tavily={bool(tavily_key)}\")\n",
    "print(f\"✓ Ready to run HealthBot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77267944",
   "metadata": {},
   "source": [
    "## Import & Initialize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b99de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import workflow components\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "# Create the compiled workflow\n",
    "app = create_healthbot_workflow()\n",
    "\n",
    "print(\"✓ Workflow imported and compiled\")\n",
    "print(\"✓ Ready for interactive session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35f809",
   "metadata": {},
   "source": [
    "## Run Interactive HealthBot Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be194e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "# Configuration with thread ID for checkpointing\n",
    "config = {\"configurable\": {\"thread_id\": \"notebook-session-1\"}}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Run the workflow\n",
    "try:\n",
    "    result = app.invoke(initial_state, config)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b6946",
   "metadata": {},
   "source": [
    "## Architecture: 8-Node Workflow with Dynamic Questions\n",
    "\n",
    "### Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic** - Gathers patient's health question\n",
    "2. **search_medical_info** - Tavily search for credible sources\n",
    "3. **summarize_results** - LLM summarization at 8th-grade level\n",
    "4. **present_summary** - Display summary and sources\n",
    "5. **generate_quiz** - LLM generates NEW quiz question (different each time)\n",
    "6. **present_quiz** - Display question with 4 options\n",
    "7. **evaluate_answer** - LLM grades with feedback\n",
    "8. **ask_continue** - 3-way routing:\n",
    "   - More questions → Generate new question on same topic (Node 5)\n",
    "   - New topic → Start over (Node 1)\n",
    "   - Exit → End session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "Unlike traditional systems that repeat the same question, HealthBot generates **different questions for each attempt**:\n",
    "- Node 5 explicitly instructs the LLM to create a NEW question not previously asked\n",
    "- Enables **deeper learning** through multiple angles\n",
    "- Prevents **memorization** rather than understanding\n",
    "- Multiple **checkpoints for comprehension**\n",
    "\n",
    "### Tech Stack:\n",
    "- **LangGraph 0.2.19** - Workflow orchestration with conditional routing\n",
    "- **OpenAI ChatOpenAI** - Language model\n",
    "- **Tavily Search API** - Medical information retrieval\n",
    "- **Python 3.8+** - Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52906f",
   "metadata": {},
   "source": [
    "## Setup: Environment & Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305dadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Project paths\n",
    "project_root = Path(r\"c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\")\n",
    "src_path = project_root / \"healthbot\" / \"src\"\n",
    "\n",
    "# Load credentials from .env\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Mark that env is loaded so modules skip redundant loading\n",
    "os.environ['ENV_ALREADY_LOADED'] = 'true'\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Credentials loaded: OpenAI={bool(openai_key)}, Tavily={bool(tavily_key)}\")\n",
    "print(f\"✓ Ready to run HealthBot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350d535",
   "metadata": {},
   "source": [
    "## Import & Initialize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import workflow components\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "# Create the compiled workflow\n",
    "app = create_healthbot_workflow()\n",
    "\n",
    "print(\"✓ Workflow imported and compiled\")\n",
    "print(\"✓ Ready for interactive session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f511f7",
   "metadata": {},
   "source": [
    "## Run Interactive HealthBot Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837366e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "# Configuration with thread ID for checkpointing\n",
    "config = {\"configurable\": {\"thread_id\": \"notebook-session-1\"}}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Run the workflow\n",
    "try:\n",
    "    result = app.invoke(initial_state, config)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370da0c",
   "metadata": {},
   "source": [
    "## Architecture: 8-Node Workflow with Dynamic Questions\n",
    "\n",
    "### Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic** - Gathers patient's health question\n",
    "2. **search_medical_info** - Tavily search for credible sources\n",
    "3. **summarize_results** - LLM summarization at 8th-grade level\n",
    "4. **present_summary** - Display summary and sources\n",
    "5. **generate_quiz** - LLM generates NEW quiz question (different each time)\n",
    "6. **present_quiz** - Display question with 4 options\n",
    "7. **evaluate_answer** - LLM grades with feedback\n",
    "8. **ask_continue** - 3-way routing:\n",
    "   - More questions → Generate new question on same topic (Node 5)\n",
    "   - New topic → Start over (Node 1)\n",
    "   - Exit → End session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "Unlike traditional systems that repeat the same question, HealthBot generates **different questions for each attempt**:\n",
    "- Node 5 explicitly instructs the LLM to create a NEW question not previously asked\n",
    "- Enables **deeper learning** through multiple angles\n",
    "- Prevents **memorization** rather than understanding\n",
    "- Multiple **checkpoints for comprehension**\n",
    "\n",
    "### Tech Stack:\n",
    "- **LangGraph 0.2.19** - Workflow orchestration with conditional routing\n",
    "- **OpenAI ChatOpenAI** - Language model\n",
    "- **Tavily Search API** - Medical information retrieval\n",
    "- **Python 3.8+** - Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859fbef",
   "metadata": {},
   "source": [
    "## Setup: Environment & Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Use absolute path to project root where .env is located\n",
    "project_root = Path(r\"c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\")\n",
    "src_path = project_root / \"healthbot\" / \"src\"\n",
    "\n",
    "# Load .env IMMEDIATELY so it's available for module initialization\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Mark that env is already loaded - this tells modules to skip loading\n",
    "os.environ['ENV_ALREADY_LOADED'] = 'true'\n",
    "\n",
    "# Add src to path and change working directory\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Src path: {src_path}\")\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")\n",
    "print(f\"✓ ENV_ALREADY_LOADED marker set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a21b2b",
   "metadata": {},
   "source": [
    "## Load Environment & Verify Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a509fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify credentials (already loaded in cell 3)\n",
    "openai_key = os.getenv('OPENAI_API_KEY', '').strip()\n",
    "tavily_key = os.getenv('TAVILY_API_KEY', '').strip()\n",
    "foundry_endpoint = os.getenv('FOUNDRY_PROJECT_ENDPOINT', '').strip()\n",
    "\n",
    "env_path = project_root / '.env'\n",
    "print(f\"✓ .env file: {env_path}\")\n",
    "print(f\"✓ File exists: {env_path.exists()}\")\n",
    "print(f\"✓ OpenAI API Key loaded: {'Yes' if openai_key else 'No'}\")\n",
    "print(f\"✓ Tavily API Key loaded: {'Yes' if tavily_key else 'No'}\")\n",
    "print(f\"✓ Foundry Endpoint loaded: {'Yes' if foundry_endpoint else 'No'}\")\n",
    "\n",
    "if not tavily_key:\n",
    "    raise ValueError(\"Missing TAVILY_API_KEY in .env\")\n",
    "print(\"✓ All required credentials verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d3746",
   "metadata": {},
   "source": [
    "## Import HealthBot Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from llm_config import initialize_llm\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "print(\"✓ llm_config imported\")\n",
    "print(\"✓ workflow imported\")\n",
    "print(\"✓ All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e679519",
   "metadata": {},
   "source": [
    "## Initialize LLM & Create Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113eee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM directly (credentials already in environment from cell 5)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Use OpenAI with credentials already loaded in environment\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "print(f\"✓ LLM initialized: {llm.__class__.__name__}\")\n",
    "\n",
    "# Create workflow\n",
    "from workflow import create_healthbot_workflow\n",
    "app = create_healthbot_workflow()\n",
    "print(\"✓ Workflow created\")\n",
    "print(f\"✓ Workflow compiled and ready to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485170f9",
   "metadata": {},
   "source": [
    "## Initialize State & Run Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "print(\"✓ Initial state prepared\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the HealthBot CLI script which handles environment loading properly\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "cli_script = project_root / \"healthbot\" / \"run_healthbot.py\"\n",
    "\n",
    "print(f\"Running: {cli_script}\\n\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, str(cli_script)],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=False,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Session completed successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n❌ CLI script exited with code {result.returncode}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error running CLI script: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ece16a",
   "metadata": {},
   "source": [
    "## Architecture Overview: 8-Node Workflow with Dynamic Question Generation\n",
    "\n",
    "### Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic**: Gathers patient's health question with validation\n",
    "2. **search_medical_info**: Uses Tavily API to find credible medical sources (5 sources)\n",
    "3. **summarize_results**: LLM summarizes at 8th-grade reading level\n",
    "4. **present_summary**: Displays summary and sources to patient\n",
    "5. **generate_quiz**: LLM generates quiz question (different for each attempt)\n",
    "6. **present_quiz**: Displays question with 4 multiple-choice options\n",
    "7. **evaluate_answer**: LLM grades answer and provides feedback with citations\n",
    "8. **ask_continue**: 3-way routing:\n",
    "   - \"1\" → More questions (loops to Node 5 with new question)\n",
    "   - \"2\" → New topic (loops to Node 1)\n",
    "   - \"3\" → Exit session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "**Problem**: Traditional quiz systems ask the same question repeatedly, leading to memorization rather than learning.\n",
    "\n",
    "**Solution**: HealthBot generates **different questions for each attempt** on the same topic. Node 5 checks `quiz_count` and explicitly instructs LLM: \"Generate a NEW question, not the one previously asked.\"\n",
    "\n",
    "**Benefits**:\n",
    "- **Deeper learning**: Multiple angles on same topic\n",
    "- **Better retention**: Prevents memorization\n",
    "- **Comprehensive assessment**: Multiple checkpoints for understanding\n",
    "\n",
    "### Technology Stack:\n",
    "- **LangGraph 0.2.19**: Workflow orchestration with conditional routing\n",
    "- **OpenAI ChatOpenAI**: Language model for summarization and grading  \n",
    "- **Tavily Search API**: Medical information retrieval with credible sources\n",
    "- **Python 3.8+**: Implementation language\n",
    "\n",
    "### Message Flow:\n",
    "```\n",
    "Patient Input\n",
    "    ↓\n",
    "Search Tavily → Get 5 Sources\n",
    "    ↓\n",
    "Summarize → 8th Grade Level\n",
    "    ↓\n",
    "Present Summary\n",
    "    ↓\n",
    "Generate NEW Quiz Question (different each time)\n",
    "    ↓\n",
    "Get Patient Answer\n",
    "    ↓\n",
    "Grade with LLM → Feedback + Citations\n",
    "    ↓\n",
    "Continue? (More Questions | New Topic | Exit)\n",
    "    ↓\n",
    "Loop back or End Session\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab5c4b",
   "metadata": {},
   "source": [
    "## Setup: Environment & Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# The .env is at: c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\\.env\n",
    "# Use absolute path to be sure it works\n",
    "project_root = Path(r\"c:\\Training\\Udacity\\AI_Agents_LangGraph\\project\")\n",
    "src_path = project_root / \"healthbot\" / \"src\"\n",
    "\n",
    "# Add src to path and change working directory\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Src path added: {src_path}\")\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8a026",
   "metadata": {},
   "source": [
    "## Load Environment & Verify Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37614b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from project root\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY', '').strip()\n",
    "tavily_key = os.getenv('TAVILY_API_KEY', '').strip()\n",
    "\n",
    "print(f\"✓ .env file: {env_path}\")\n",
    "print(f\"✓ File exists: {env_path.exists()}\")\n",
    "print(f\"✓ OpenAI API Key loaded: {'Yes' if openai_key else 'No'}\")\n",
    "print(f\"✓ Tavily API Key loaded: {'Yes' if tavily_key else 'No'}\")\n",
    "\n",
    "if not openai_key or not tavily_key:\n",
    "    raise ValueError(\"Missing required credentials in .env\")\n",
    "print(\"✓ All credentials verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b674f4",
   "metadata": {},
   "source": [
    "## Import HealthBot Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from llm_config import initialize_llm\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "print(\"✓ llm_config imported\")\n",
    "print(\"✓ workflow imported\")\n",
    "print(\"✓ All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefd2da",
   "metadata": {},
   "source": [
    "## Initialize LLM & Create Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = initialize_llm()\n",
    "print(f\"✓ LLM initialized: {llm.__class__.__name__}\")\n",
    "\n",
    "# Create workflow\n",
    "app = create_healthbot_workflow()\n",
    "print(\"✓ Workflow created\")\n",
    "print(f\"✓ Workflow compiled and ready to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8f804",
   "metadata": {},
   "source": [
    "## Initialize State & Run Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "print(\"✓ Initial state prepared\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ba754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow interactively\n",
    "try:\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    # Display final session summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Health Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Final Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Quiz Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages Exchanged: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c5b7a",
   "metadata": {},
   "source": [
    "## Architecture Overview: 8-Node Workflow with Dynamic Question Generation\n",
    "\n",
    "### Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic**: Gathers patient's health question with validation\n",
    "2. **search_medical_info**: Uses Tavily API to find credible medical sources (5 sources)\n",
    "3. **summarize_results**: LLM summarizes at 8th-grade reading level\n",
    "4. **present_summary**: Displays summary and sources to patient\n",
    "5. **generate_quiz**: LLM generates quiz question (different for each attempt)\n",
    "6. **present_quiz**: Displays question with 4 multiple-choice options\n",
    "7. **evaluate_answer**: LLM grades answer and provides feedback with citations\n",
    "8. **ask_continue**: 3-way routing:\n",
    "   - \"1\" → More questions (loops to Node 5 with new question)\n",
    "   - \"2\" → New topic (loops to Node 1)\n",
    "   - \"3\" → Exit session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "**Problem**: Traditional quiz systems ask the same question repeatedly, leading to memorization rather than learning.\n",
    "\n",
    "**Solution**: HealthBot generates **different questions for each attempt** on the same topic. Node 5 checks `quiz_count` and explicitly instructs LLM: \"Generate a NEW question, not the one previously asked.\"\n",
    "\n",
    "**Benefits**:\n",
    "- **Deeper learning**: Multiple angles on same topic\n",
    "- **Better retention**: Prevents memorization\n",
    "- **Comprehensive assessment**: Multiple checkpoints for understanding\n",
    "\n",
    "### Technology Stack:\n",
    "- **LangGraph 0.2.19**: Workflow orchestration with conditional routing\n",
    "- **OpenAI ChatOpenAI**: Language model for summarization and grading  \n",
    "- **Tavily Search API**: Medical information retrieval with credible sources\n",
    "- **Python 3.8+**: Implementation language\n",
    "\n",
    "### Message Flow:\n",
    "```\n",
    "Patient Input\n",
    "    ↓\n",
    "Search Tavily → Get 5 Sources\n",
    "    ↓\n",
    "Summarize → 8th Grade Level\n",
    "    ↓\n",
    "Present Summary\n",
    "    ↓\n",
    "Generate NEW Quiz Question (different each time)\n",
    "    ↓\n",
    "Get Patient Answer\n",
    "    ↓\n",
    "Grade with LLM → Feedback + Citations\n",
    "    ↓\n",
    "Continue? (More Questions | New Topic | Exit)\n",
    "    ↓\n",
    "Loop back or End Session\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8fd27d",
   "metadata": {},
   "source": [
    "## Setup: Environment & Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147497f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to project root (.env location)\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent  # notebooks -> healthbot -> project\n",
    "src_path = project_root / 'healthbot' / 'src'\n",
    "\n",
    "# Add src to path for module imports\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Src path added: {src_path}\")\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77286072",
   "metadata": {},
   "source": [
    "## Load Environment & Verify Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from project root\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY', '').strip()\n",
    "tavily_key = os.getenv('TAVILY_API_KEY', '').strip()\n",
    "\n",
    "print(f\"✓ .env file: {env_path}\")\n",
    "print(f\"✓ File exists: {env_path.exists()}\")\n",
    "print(f\"✓ OpenAI API Key loaded: {'Yes' if openai_key else 'No'}\")\n",
    "print(f\"✓ Tavily API Key loaded: {'Yes' if tavily_key else 'No'}\")\n",
    "\n",
    "if not openai_key or not tavily_key:\n",
    "    raise ValueError(\"Missing required credentials in .env\")\n",
    "print(\"✓ All credentials verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9decc24a",
   "metadata": {},
   "source": [
    "## Import HealthBot Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a891407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from llm_config import initialize_llm\n",
    "from state import HealthBotState\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "print(\"✓ llm_config imported\")\n",
    "print(\"✓ state imported\")\n",
    "print(\"✓ workflow imported\")\n",
    "print(\"✓ All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de46c4",
   "metadata": {},
   "source": [
    "## Initialize LLM & Create Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d729d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = initialize_llm()\n",
    "print(f\"✓ LLM initialized: {llm.__class__.__name__}\")\n",
    "\n",
    "# Create workflow\n",
    "app = create_healthbot_workflow()\n",
    "print(\"✓ Workflow created\")\n",
    "print(f\"✓ Workflow compiled and ready to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c7e24",
   "metadata": {},
   "source": [
    "## Initialize State & Run Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d551e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "print(\"✓ Initial state prepared\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99664856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow interactively\n",
    "try:\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    # Display final session summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Health Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Final Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Quiz Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages Exchanged: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945ef64",
   "metadata": {},
   "source": [
    "## Architecture Overview: 8-Node Workflow with Dynamic Question Generation\n",
    "\n",
    "### Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic**: Gathers patient's health question with validation\n",
    "2. **search_medical_info**: Uses Tavily API to find credible medical sources (5 sources)\n",
    "3. **summarize_results**: LLM summarizes at 8th-grade reading level\n",
    "4. **present_summary**: Displays summary and sources to patient\n",
    "5. **generate_quiz**: LLM generates quiz question (different for each attempt)\n",
    "6. **present_quiz**: Displays question with 4 multiple-choice options\n",
    "7. **evaluate_answer**: LLM grades answer and provides feedback with citations\n",
    "8. **ask_continue**: 3-way routing:\n",
    "   - \"1\" → More questions (loops to Node 5 with new question)\n",
    "   - \"2\" → New topic (loops to Node 1)\n",
    "   - \"3\" → Exit session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "**Problem**: Traditional quiz systems ask the same question repeatedly, leading to memorization rather than learning.\n",
    "\n",
    "**Solution**: HealthBot generates **different questions for each attempt** on the same topic. Node 5 checks `quiz_count` and explicitly instructs LLM: \"Generate a NEW question, not the one previously asked.\"\n",
    "\n",
    "**Benefits**:\n",
    "- **Deeper learning**: Multiple angles on same topic\n",
    "- **Better retention**: Prevents memorization\n",
    "- **Comprehensive assessment**: Multiple checkpoints for understanding\n",
    "\n",
    "### Technology Stack:\n",
    "- **LangGraph 0.2.19**: Workflow orchestration with conditional routing\n",
    "- **OpenAI ChatOpenAI**: Language model for summarization and grading  \n",
    "- **Tavily Search API**: Medical information retrieval with credible sources\n",
    "- **Python 3.8+**: Implementation language\n",
    "\n",
    "### Message Flow:\n",
    "```\n",
    "Patient Input\n",
    "    ↓\n",
    "Search Tavily → Get 5 Sources\n",
    "    ↓\n",
    "Summarize → 8th Grade Level\n",
    "    ↓\n",
    "Present Summary\n",
    "    ↓\n",
    "Generate NEW Quiz Question (different each time)\n",
    "    ↓\n",
    "Get Patient Answer\n",
    "    ↓\n",
    "Grade with LLM → Feedback + Citations\n",
    "    ↓\n",
    "Continue? (More Questions | New Topic | Exit)\n",
    "    ↓\n",
    "Loop back or End Session\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36408c81",
   "metadata": {},
   "source": [
    "## Architecture Overview: 8-Node Workflow with Dynamic Question Generation\n",
    "\n",
    "### Workflow Nodes:\n",
    "\n",
    "1. **ask_for_topic**: Gathers patient's health question with validation\n",
    "2. **search_medical_info**: Uses Tavily API to find credible medical sources (5 sources)\n",
    "3. **summarize_results**: LLM summarizes at 8th-grade reading level\n",
    "4. **present_summary**: Displays summary and sources to patient\n",
    "5. **generate_quiz**: LLM generates quiz question (different for each attempt)\n",
    "6. **present_quiz**: Displays question with 4 multiple-choice options\n",
    "7. **evaluate_answer**: LLM grades answer and provides feedback with citations\n",
    "8. **ask_continue**: 3-way routing:\n",
    "   - \"1\" → More questions (loops to Node 5 with new question)\n",
    "   - \"2\" → New topic (loops to Node 1)\n",
    "   - \"3\" → Exit session\n",
    "\n",
    "### Stand-Out Feature: Dynamic Question Generation\n",
    "\n",
    "**Problem**: Traditional quiz systems ask the same question repeatedly, leading to memorization rather than learning.\n",
    "\n",
    "**Solution**: HealthBot generates **different questions for each attempt** on the same topic. Node 5 checks `quiz_count` and explicitly instructs LLM: \"Generate a NEW question, not the one previously asked.\"\n",
    "\n",
    "**Benefits**:\n",
    "- **Deeper learning**: Multiple angles on same topic\n",
    "- **Better retention**: Prevents memorization\n",
    "- **Comprehensive assessment**: Multiple checkpoints for understanding\n",
    "\n",
    "### Technology Stack:\n",
    "- **LangGraph 0.2.19**: Workflow orchestration with conditional routing\n",
    "- **OpenAI ChatOpenAI**: Language model for summarization and grading  \n",
    "- **Tavily Search API**: Medical information retrieval with credible sources\n",
    "- **Python 3.8+**: Implementation language\n",
    "\n",
    "### Message Flow:\n",
    "```\n",
    "Patient Input\n",
    "    ↓\n",
    "Search Tavily → Get 5 Sources\n",
    "    ↓\n",
    "Summarize → 8th Grade Level\n",
    "    ↓\n",
    "Present Summary\n",
    "    ↓\n",
    "Generate NEW Quiz Question (different each time)\n",
    "    ↓\n",
    "Get Patient Answer\n",
    "    ↓\n",
    "Grade with LLM → Feedback + Citations\n",
    "    ↓\n",
    "Continue? (More Questions | New Topic | Exit)\n",
    "    ↓\n",
    "Loop back or End Session\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow interactively\n",
    "try:\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    # Display final session summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Health Topic: {result.get('health_topic', 'N/A')}\")\n",
    "    print(f\"Final Grade: {result.get('grade', 'N/A')}/100\")\n",
    "    print(f\"Quiz Questions Asked: {result.get('quiz_count', 0)}\")\n",
    "    print(f\"Messages Exchanged: {len(result.get('messages', []))}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✓ Session completed successfully!\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Session ended by user\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb66b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"health_topic\": None,\n",
    "    \"search_results\": None,\n",
    "    \"summary\": None,\n",
    "    \"quiz_question\": None,\n",
    "    \"patient_answer\": None,\n",
    "    \"grade\": None,\n",
    "    \"feedback\": None,\n",
    "    \"should_continue\": \"start\",\n",
    "    \"session_id\": \"notebook-session\",\n",
    "    \"quiz_count\": 0\n",
    "}\n",
    "\n",
    "print(\"✓ Initial state prepared\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HEALTHBOT INTERACTIVE SESSION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f9318",
   "metadata": {},
   "source": [
    "## Initialize State & Run Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = initialize_llm()\n",
    "print(f\"✓ LLM initialized: {llm.__class__.__name__}\")\n",
    "\n",
    "# Create workflow\n",
    "app = create_healthbot_workflow()\n",
    "print(\"✓ Workflow created\")\n",
    "print(f\"✓ Workflow compiled and ready to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318818e",
   "metadata": {},
   "source": [
    "## Initialize LLM & Create Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c907c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from llm_config import initialize_llm\n",
    "from state import HealthBotState\n",
    "from workflow import create_healthbot_workflow\n",
    "\n",
    "print(\"✓ llm_config imported\")\n",
    "print(\"✓ state imported\")\n",
    "print(\"✓ workflow imported\")\n",
    "print(\"✓ All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878397b",
   "metadata": {},
   "source": [
    "## Import HealthBot Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c16be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from project root\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify credentials\n",
    "openai_key = os.getenv('OPENAI_API_KEY', '').strip()\n",
    "tavily_key = os.getenv('TAVILY_API_KEY', '').strip()\n",
    "\n",
    "print(f\"✓ .env file: {env_path}\")\n",
    "print(f\"✓ File exists: {env_path.exists()}\")\n",
    "print(f\"✓ OpenAI API Key loaded: {'Yes' if openai_key else 'No'}\")\n",
    "print(f\"✓ Tavily API Key loaded: {'Yes' if tavily_key else 'No'}\")\n",
    "\n",
    "if not openai_key or not tavily_key:\n",
    "    raise ValueError(\"Missing required credentials in .env\")\n",
    "print(\"✓ All credentials verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa84bd",
   "metadata": {},
   "source": [
    "## Load Environment & Verify Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef789b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to project root (.env location)\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent  # notebooks -> healthbot -> project\n",
    "src_path = project_root / 'healthbot' / 'src'\n",
    "\n",
    "# Add src to path for module imports\n",
    "sys.path.insert(0, str(src_path))\n",
    "os.chdir(str(project_root))\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Src path added: {src_path}\")\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0cb2b0",
   "metadata": {},
   "source": [
    "## Setup: Environment & Path Configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
